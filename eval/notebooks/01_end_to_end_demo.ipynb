{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End-to-End DeepEval (Single Question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "34a3cf38",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepeval in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (3.8.4)\n",
            "Requirement already satisfied: aiohttp in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (3.13.3)\n",
            "Requirement already satisfied: click<8.3.0,>=8.0.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (8.2.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.67.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (1.78.0)\n",
            "Requirement already satisfied: jinja2 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (1.6.0)\n",
            "Requirement already satisfied: openai in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (2.17.0)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (1.39.1)\n",
            "Requirement already satisfied: portalocker in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (3.2.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=5.4.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (5.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.11.7 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (2.12.5)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (2.12.0)\n",
            "Requirement already satisfied: pyfiglet in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (1.0.4)\n",
            "Requirement already satisfied: pytest in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (9.0.2)\n",
            "Requirement already satisfied: pytest-asyncio in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (1.3.0)\n",
            "Requirement already satisfied: pytest-repeat in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (0.9.4)\n",
            "Requirement already satisfied: pytest-rerunfailures in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (16.1)\n",
            "Requirement already satisfied: pytest-xdist in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (3.8.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.1.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (1.2.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (2.32.5)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.6.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (14.3.2)\n",
            "Requirement already satisfied: sentry-sdk in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (2.52.0)\n",
            "Requirement already satisfied: setuptools in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (80.9.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (0.9.0)\n",
            "Requirement already satisfied: tenacity<=10.0.0,>=8.0.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (9.1.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (4.67.3)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (0.21.1)\n",
            "Requirement already satisfied: wheel in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from deepeval) (0.46.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from grpcio<2.0.0,>=1.67.1->deepeval) (4.15.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (8.7.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.39.1)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from opentelemetry-proto==1.39.1->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (6.33.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (0.60b1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->deepeval) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->deepeval) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->deepeval) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->deepeval) (2026.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from rich<15.0.0,>=13.6.0->deepeval) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from rich<15.0.0,>=13.6.0->deepeval) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.9->deepeval) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.6.0->deepeval) (0.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from aiohttp->deepeval) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from aiohttp->deepeval) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from aiohttp->deepeval) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from aiohttp->deepeval) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from aiohttp->deepeval) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from aiohttp->deepeval) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from aiohttp->deepeval) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from jinja2->deepeval) (3.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from openai->deepeval) (4.12.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from openai->deepeval) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from openai->deepeval) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from openai->deepeval) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->deepeval) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->deepeval) (0.16.0)\n",
            "Requirement already satisfied: iniconfig>=1.0.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from pytest->deepeval) (2.3.0)\n",
            "Requirement already satisfied: packaging>=22 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from pytest->deepeval) (26.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from pytest->deepeval) (1.6.0)\n",
            "Requirement already satisfied: execnet>=2.1 in /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/.venv/lib/python3.11/site-packages (from pytest-xdist->deepeval) (2.1.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# If needed, uncomment to install/upgrade DeepEval\n",
        "!pip install -U deepeval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3a2b531d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Backend: http://localhost:8000\n",
            "File: /Users/shubhanshurastogi_1/Learning/rag-session-qa-eval/eval/sample_docs/Match_Summary.pdf\n",
            "Publish to Confident AI: False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('./../.env')\n",
        "\n",
        "ROOT = Path('..').resolve().parent\n",
        "sys.path.append(str(ROOT))\n",
        "\n",
        "BASE_URL = os.getenv('BASE_URL', 'http://localhost:8000')\n",
        "FILE_PATH = Path(os.getenv('SAMPLE_FILE', '../sample_docs/Match_Summary.pdf')).resolve()\n",
        "PUBLISH = os.getenv('DEEPEVAL_PUBLISH', 'false').lower() == 'true'\n",
        "\n",
        "print('Backend:', BASE_URL)\n",
        "print('File:', FILE_PATH)\n",
        "print('Publish to Confident AI:', PUBLISH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c91871c8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "ROOT = Path('..').resolve().parent  # repo root\n",
        "load_dotenv(ROOT / 'backend' / '.env')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cb410ba0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
        "from deepeval.evaluate import evaluate, AsyncConfig\n",
        "from deepeval.metrics import (\n",
        "    ContextualPrecisionMetric,\n",
        "    ContextualRecallMetric,\n",
        "    AnswerRelevancyMetric,\n",
        "    FaithfulnessMetric,\n",
        ")\n",
        "\n",
        "try:\n",
        "    from deepeval.metrics import ContextualRelevancyMetric\n",
        "except Exception:\n",
        "    ContextualRelevancyMetric = None\n",
        "\n",
        "try:\n",
        "    from deepeval.metrics import CompletenessMetric\n",
        "except Exception:\n",
        "    CompletenessMetric = None\n",
        "\n",
        "try:\n",
        "    from deepeval.metrics import GEval\n",
        "except Exception:\n",
        "    GEval = None\n",
        "\n",
        "def build_metrics():\n",
        "    metrics = [\n",
        "        ContextualPrecisionMetric(),\n",
        "        ContextualRecallMetric(),\n",
        "        AnswerRelevancyMetric(),\n",
        "        FaithfulnessMetric(),\n",
        "    ]\n",
        "    if ContextualRelevancyMetric is not None:\n",
        "        metrics.append(ContextualRelevancyMetric())\n",
        "    elif GEval is not None:\n",
        "        metrics.append(\n",
        "            GEval(\n",
        "                name='Context Relevance',\n",
        "                criteria='Evaluate how relevant the retrieval context is to the question. Score 0 to 1.',\n",
        "                evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.RETRIEVAL_CONTEXT],\n",
        "            )\n",
        "        )\n",
        "    if CompletenessMetric is not None:\n",
        "        metrics.append(CompletenessMetric())\n",
        "    elif GEval is not None:\n",
        "        metrics.append(\n",
        "            GEval(\n",
        "                name='Completeness',\n",
        "                criteria='Assess if the answer is complete given the context. Score 0 to 1.',\n",
        "                evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.RETRIEVAL_CONTEXT],\n",
        "            )\n",
        "        )\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72cfe3cb",
      "metadata": {},
      "source": [
        "## Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3efd6cba",
      "metadata": {},
      "outputs": [],
      "source": [
        "QUESTION = 'How many sixes did Tilak Varma hit?'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82761c8a",
      "metadata": {},
      "source": [
        "## Upload Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cd4a520f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Session: 01560197-36ca-4e40-a14b-9ae3947a272d\n"
          ]
        }
      ],
      "source": [
        "with open(FILE_PATH, 'rb') as f:\n",
        "    files = {'file': (FILE_PATH.name, f)}\n",
        "    upload_res = requests.post(f'{BASE_URL}/upload', files=files)\n",
        "\n",
        "upload_res.raise_for_status()\n",
        "session_id = upload_res.json().get('session_id')\n",
        "print('Session:', session_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dba6edb",
      "metadata": {},
      "source": [
        "## Ask + Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7bf20114",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: Tilak Varma hit 3 sixes.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Completeness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mCompleteness \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a23bc6528784a699f8198f8fe8a59ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The score is 1.00 because the top-ranked node directly answers the question with the quote 'Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]', clearly stating the number of sixes hit. Great job!, error: None)\n",
            "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The score is 1.00 because the node(s) in retrieval context directly confirm that Tilak Varma hit 3 sixes, perfectly matching the expected output., error: None)\n",
            "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The score is 1.00 because the answer was fully relevant and directly addressed the question without any irrelevant information. Great job staying focused and concise!, error: None)\n",
            "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The score is 1.00 because there are no contradictions‚Äîgreat job staying true to the retrieval context!, error: None)\n",
            "  - ‚ùå Contextual Relevancy (score: 0.25, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The score is 0.25 because most of the context is about other players or fours, not sixes by Tilak Varma, but there is one relevant statement: 'Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]' which directly answers the input., error: None)\n",
            "  - ‚úÖ Completeness [GEval] (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The response directly answers the question by stating that Tilak Varma hit 3 sixes, which is fully supported by the retrieval context showing '[4s-3 6s-3]' in his score summary. The answer is complete and accurately uses the provided context., error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: How many sixes did Tilak Varma hit?\n",
            "  - actual output: Tilak Varma hit 3 sixes.\n",
            "  - expected output: Tilak Varma hit 3 sixes.\n",
            "  - context: None\n",
            "  - retrieval context: [\"aren't in use today so it took some time for everyone to realise what happened. A yorker from round the wicket, looks to flick it away, misses and it clips leg stump on the way. Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3] 10.5 4 Marco Jansen to Tilak Varma, FOUR, round the wicket, short of length across off, and it's swatted wide of mid-on. Fielder gets a hand diving across but it still runs away 10.2 Marco Jansen to Suryakumar Yadav, 1 run, dropped! Suryakumar having all the luck out there! Length ball on leg, tries his trademark scoop but is through the shot early. Toe-ends it in the air to deep midwicket and Bosch makes a meal of it 10.1 4 Marco Jansen to Suryakumar Yadav, FOUR, another inside edge past the stumps! Good length across off, he looks to loft down the ground but the\"]\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "Contextual Precision: 100.00% pass rate\n",
            "Contextual Recall: 100.00% pass rate\n",
            "Answer Relevancy: 100.00% pass rate\n",
            "Faithfulness: 100.00% pass rate\n",
            "Contextual Relevancy: 0.00% pass rate\n",
            "Completeness [GEval]: 100.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
              "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
              "¬ª \u001b]8;id=223020;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34.</span>52s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.024502</span> USD<span style=\"font-weight: bold\">)</span>\n",
              "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
              "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
              "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
              "\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n",
              "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m34.\u001b[0m52s | token cost: \u001b[1;36m0.024502\u001b[0m USD\u001b[1m)\u001b[0m\n",
              "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
              "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
              "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "EvaluationResult(test_results=[TestResult(name='test_case_0', success=False, metrics_data=[MetricData(name='Contextual Precision', threshold=0.5, success=True, score=1.0, reason=\"The score is 1.00 because the top-ranked node directly answers the question with the quote 'Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]', clearly stating the number of sixes hit. Great job!\", strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.00355, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context contains the line \\'Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]\\', which directly states that Tilak Varma hit 3 sixes.\"\\n    }\\n]'), MetricData(name='Contextual Recall', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because the node(s) in retrieval context directly confirm that Tilak Varma hit 3 sixes, perfectly matching the expected output.', strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.0029639999999999996, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The 1st node states: \\'Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]\\', which indicates Tilak Varma hit 3 sixes.\",\\n        \"expected_output\": \"Tilak Varma hit 3 sixes.\"\\n    }\\n]'), MetricData(name='Answer Relevancy', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because the answer was fully relevant and directly addressed the question without any irrelevant information. Great job staying focused and concise!', strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.0028460000000000004, verbose_logs='Statements:\\n[\\n    \"Tilak Varma hit 3 sixes.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'), MetricData(name='Faithfulness', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because there are no contradictions‚Äîgreat job staying true to the retrieval context!', strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.0066619999999999995, verbose_logs='Truths (limit=None):\\n[\\n    \"A yorker from round the wicket clipped leg stump after the batsman missed while trying to flick it away.\",\\n    \"Tilak Varma was bowled by Marco Jansen after scoring 45 runs off 19 balls, including 3 fours and 3 sixes.\",\\n    \"On ball 10.5, Marco Jansen bowled round the wicket, short of length across off, and Tilak Varma hit a four wide of mid-on despite a fielder\\'s diving effort.\",\\n    \"On ball 10.2, Marco Jansen bowled to Suryakumar Yadav, who was dropped at deep midwicket by Bosch after toe-ending a scoop shot.\",\\n    \"On ball 10.1, Marco Jansen bowled a good length ball across off to Suryakumar Yadav, who hit a four via an inside edge past the stumps.\"\\n] \\n \\nClaims:\\n[\\n    \"Tilak Varma hit 3 sixes.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'), MetricData(name='Contextual Relevancy', threshold=0.5, success=False, score=0.25, reason=\"The score is 0.25 because most of the context is about other players or fours, not sixes by Tilak Varma, but there is one relevant statement: 'Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]' which directly answers the input.\", strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.005861999999999999, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]\",\\n                \"verdict\": \"yes\",\\n                \"reason\": \"This statement provides the number of sixes (6s-3) hit by Tilak Varma, which directly answers the input question.\"\\n            },\\n            {\\n                \"statement\": \"Marco Jansen to Tilak Varma, FOUR, round the wicket, short of length across off, and it\\'s swatted wide of mid-on. Fielder gets a hand diving across but it still runs away\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"This statement describes a four hit by Tilak Varma, not a six, and thus does not answer the question about sixes.\"\\n            },\\n            {\\n                \"statement\": \"Marco Jansen to Suryakumar Yadav, 1 run, dropped! Suryakumar having all the luck out there! Length ball on leg, tries his trademark scoop but is through the shot early. Toe-ends it in the air to deep midwicket and Bosch makes a meal of it\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"This statement is about Suryakumar Yadav, not Tilak Varma, and does not mention sixes.\"\\n            },\\n            {\\n                \"statement\": \"Marco Jansen to Suryakumar Yadav, FOUR, another inside edge past the stumps! Good length across off, he looks to loft down the ground but the\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"This statement is about Suryakumar Yadav and a four, not about Tilak Varma or sixes.\"\\n            }\\n        ]\\n    }\\n]'), MetricData(name='Completeness [GEval]', threshold=0.5, success=True, score=1.0, reason=\"The response directly answers the question by stating that Tilak Varma hit 3 sixes, which is fully supported by the retrieval context showing '[4s-3 6s-3]' in his score summary. The answer is complete and accurately uses the provided context.\", strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.0026179999999999997, verbose_logs='Criteria:\\nAssess if the answer is complete given the context. Score 0 to 1. \\n \\nEvaluation Steps:\\n[\\n    \"Read the Input to understand the question or request.\",\\n    \"Review the Retrieval Context to identify all relevant information provided.\",\\n    \"Compare the Actual Output to the Input and Retrieval Context to determine if the answer addresses all aspects of the question using the available context.\",\\n    \"Decide if the Actual Output is complete, missing, or partially addressing the Input based on the context.\"\\n] \\n \\nRubric:\\nNone \\n \\nScore: 1.0')], conversational=False, multimodal=False, input='How many sixes did Tilak Varma hit?', actual_output='Tilak Varma hit 3 sixes.', expected_output='Tilak Varma hit 3 sixes.', context=None, retrieval_context=[\"aren't in use today so it took some time for everyone to realise what happened. A yorker from round the wicket, looks to flick it away, misses and it clips leg stump on the way. Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3] 10.5 4 Marco Jansen to Tilak Varma, FOUR, round the wicket, short of length across off, and it's swatted wide of mid-on. Fielder gets a hand diving across but it still runs away 10.2 Marco Jansen to Suryakumar Yadav, 1 run, dropped! Suryakumar having all the luck out there! Length ball on leg, tries his trademark scoop but is through the shot early. Toe-ends it in the air to deep midwicket and Bosch makes a meal of it 10.1 4 Marco Jansen to Suryakumar Yadav, FOUR, another inside edge past the stumps! Good length across off, he looks to loft down the ground but the\"], turns=None, additional_metadata=None)], confident_link=None, test_run_id=None)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "payload = {'session_id': session_id, 'question': QUESTION}\n",
        "ask_res = requests.post(f'{BASE_URL}/ask', json=payload)\n",
        "ask_res.raise_for_status()\n",
        "ask_data = ask_res.json()\n",
        "answer = ask_data.get('answer', '')\n",
        "retrieval_context = ask_data.get('retrieval_context', [])\n",
        "print('Answer:', answer)\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input=QUESTION,\n",
        "    actual_output=answer,\n",
        "    expected_output=answer,\n",
        "    retrieval_context=retrieval_context,\n",
        ")\n",
        "\n",
        "metrics = build_metrics()\n",
        "evaluate(\n",
        "    test_cases=[test_case],\n",
        "    metrics=metrics,\n",
        "    async_config=AsyncConfig(run_async=False)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec45720ad22544a3acfaf5fe094c2a56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3d34055f18d4b0bb3d4e54149dce1a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8abee8514f0745e29381bb5580baefba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f23f9cbfc398410d8e969addf1ab887e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d298087ea8e4bf6a0aa1d73d7a40f40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8bb73459abe4219b7eb09ac7741e585",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>score</th>\n",
              "      <th>reason</th>\n",
              "      <th>success</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ContextualPrecisionMetric</td>\n",
              "      <td>1.00</td>\n",
              "      <td>The score is 1.00 because the first node in th...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ContextualRecallMetric</td>\n",
              "      <td>1.00</td>\n",
              "      <td>The score is 1.00 because the node(s) in retri...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AnswerRelevancyMetric</td>\n",
              "      <td>1.00</td>\n",
              "      <td>The score is 1.00 because the answer was fully...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FaithfulnessMetric</td>\n",
              "      <td>1.00</td>\n",
              "      <td>The score is 1.00 because there are no contrad...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ContextualRelevancyMetric</td>\n",
              "      <td>0.25</td>\n",
              "      <td>The score is 0.25 because only one statement, ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Completeness</td>\n",
              "      <td>1.00</td>\n",
              "      <td>The Actual Output correctly states that Tilak ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      metric  score  \\\n",
              "0  ContextualPrecisionMetric   1.00   \n",
              "1     ContextualRecallMetric   1.00   \n",
              "2      AnswerRelevancyMetric   1.00   \n",
              "3         FaithfulnessMetric   1.00   \n",
              "4  ContextualRelevancyMetric   0.25   \n",
              "5               Completeness   1.00   \n",
              "\n",
              "                                              reason  success  \n",
              "0  The score is 1.00 because the first node in th...     True  \n",
              "1  The score is 1.00 because the node(s) in retri...     True  \n",
              "2  The score is 1.00 because the answer was fully...     True  \n",
              "3  The score is 1.00 because there are no contrad...     True  \n",
              "4  The score is 0.25 because only one statement, ...    False  \n",
              "5  The Actual Output correctly states that Tilak ...     True  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_rows = []\n",
        "for metric in build_metrics():\n",
        "    metric.measure(test_case)\n",
        "    score_rows.append({\n",
        "        'metric': getattr(metric, 'name', metric.__class__.__name__),\n",
        "        'score': getattr(metric, 'score', None),\n",
        "        'reason': getattr(metric, 'reason', None),\n",
        "        'success': getattr(metric, 'success', None),\n",
        "    })\n",
        "pd.DataFrame(score_rows)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
